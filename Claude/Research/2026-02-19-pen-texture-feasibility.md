# Feasibility: Adding Textures to Pencil and Brush Pen Types

**Date:** 2026-02-19
**Purpose:** Assess the feasibility, approaches, and tradeoffs of adding realistic textures to the pencil and brush pen types in ObsidianPaper. Includes findings from web research on industry approaches, open-source implementations, and performance considerations.

---

## Current State

ObsidianPaper renders strokes as **solid-color filled Path2D polygons** generated by the `perfect-freehand` library. The pipeline is:

1. Input points (with pressure/tilt/twist) are smoothed
2. `PenEngine` computes per-point width and opacity
3. `OutlineGenerator` produces an outline polygon via `perfect-freehand`
4. The polygon becomes a cached `Path2D` object
5. `Renderer` fills the path with `ctx.fill(path)` using a solid `fillStyle` and `globalAlpha`

The pencil already has **pressure-driven opacity** (`pressureOpacityRange: [0.15, 0.85]`) and **tilt sensitivity** (wider + lighter when tilted), which gives it some character. But the output is still a smooth, uniform fill — it doesn't look like graphite on paper.

---

## What Makes Pencil/Brush Look Realistic

### Pencil
Real graphite has three visual characteristics:
1. **Grain/texture** — graphite deposits unevenly across paper fibers, creating a noisy, granular appearance. Light strokes show the paper "peaks" more than "valleys."
2. **Pressure-dependent coverage** — light pressure only touches paper peaks (low coverage, lots of white space visible). Heavy pressure fills valleys too (denser, more solid).
3. **Edge roughness** — pencil strokes don't have smooth edges; the boundary is irregular following paper grain.

### Brush
Real brushes have:
1. **Bristle marks** — visible parallel streaks from individual hairs, especially on dry brush strokes
2. **Paint density variation** — thicker in the center, thinner at edges
3. **Loading/unloading** — strokes start opaque and become drier/more transparent as paint depletes (out of scope for now)

---

## How Existing Apps Handle This

### Excalidraw — No Pencil Texture
Excalidraw uses [Rough.js](https://roughjs.com/) for its hand-drawn aesthetic on geometric shapes (intentional path distortion) and `perfect-freehand` for freehand strokes (solid Path2D fill, same as us). It does **not** implement pencil grain textures. The "sketchy" look comes from path randomization, not texture.

Sources: [Excalidraw GitHub](https://github.com/excalidraw/excalidraw), [PR #3512 (perfect-freehand integration)](https://github.com/excalidraw/excalidraw/pull/3512)

### tldraw — No Pencil Texture
tldraw uses `perfect-freehand` with streamline/smoothing/thinning parameters. It renders to SVG `<path>` elements with solid fills. No grain textures. Its sophistication is in the stroke algorithm, not visual texture. Useful pattern: at low zoom (`zoomLevel < 0.5 && zoomLevel < 1.5 / strokeWidth`), it switches to solid rendering — a LOD strategy we already implement.

Source: [tldraw Draw Shape Docs](https://tldraw.dev/sdk-features/draw-shape)

### Procreate — Stamp + Grain (Industry Standard)
Procreate's brush engine uses two texture layers per brush:
- **Shape** — the brush tip stamp image, placed along the stroke path at configurable spacing
- **Grain** — a paper texture tiled across the canvas that modulates the stamp's alpha

Key parameters: spacing (% of stamp size), scatter/jitter (lateral offset), opacity jitter, rotation jitter, size jitter, flow (paint density per stamp). Pressure controls opacity and size. Tilt controls shading width and grain visibility.

Source: [Procreate Brush Studio Settings](https://help.procreate.com/procreate/handbook/brushes/brush-studio-settings)

### Krita — Texture Modes on Brush Dabs (Open Source Reference)
Krita's brush engine applies texture as a separate layer modulating the brush dab's alpha:
- **Multiply mode**: `output_alpha = dab_alpha * texture_value` — soft, natural feel
- **Subtract mode**: `output_alpha = max(0, dab_alpha - (texture_value + (1 - strength)))` — harsher, more visible grain
- **Cutoff**: grayscale range limiting for the texture, controlling which parts affect the brush
- **Strength**: controls how strongly the texture affects the dab

Krita's pencil presets combine a paper texture with Subtract or Multiply mode. This is the most well-documented open-source approach.

Source: [Krita Texture Documentation](https://docs.krita.org/en/reference_manual/brushes/brush_settings/texture.html)

### Academic: "Real-Time Pencil Rendering" (Lee et al., NPAR 2006)
Models paper as a height field. Graphite only deposits on "peaks" — valleys remain empty. Pressure flattens the paper (filling valleys at high pressure). Uses pre-computed texture screens rather than per-pixel physics for GPU performance. Achieves 15-60fps for 3D meshes.

**Key insight for us**: The paper-height-field concept simplifies to: grain texture brightness = paper surface height. `multiply` compositing naturally simulates "graphite on peaks only."

Source: [Real-Time Pencil Rendering (PDF)](https://static.aminer.org/pdf/PDF/000/519/757/real_time_pencil_rendering.pdf)

---

## Approaches (Updated with Research)

### Approach 1: Clip + Pattern Fill (RECOMMENDED — Best Performance)

**How it works:** Fill the stroke solid, then clip to the stroke shape and overlay a tiled grain pattern using compositing. This is the simplest approach that works with our existing Path2D pipeline.

**Implementation:**
```typescript
// One-time setup: generate grain pattern
const grainPattern = ctx.createPattern(grainCanvas, "repeat")!;

// Per-stroke render:
ctx.save();
ctx.fillStyle = strokeColor;
ctx.fill(path2d);                         // 1. Solid fill
ctx.clip(path2d);                          // 2. Clip to stroke shape
ctx.globalCompositeOperation = "multiply"; // 3. Grain darkens the fill
ctx.globalAlpha = grainIntensity;          // 4. Control texture strength
ctx.fillStyle = grainPattern;
ctx.fillRect(bounds.x, bounds.y, bounds.w, bounds.h);
ctx.restore();
```

**Why screen-space is correct here:** For paper grain, screen-space texture is actually physically accurate. Real paper grain is fixed — the pencil moves across it. The texture should stay anchored to the page, not follow the stroke. We just need to offset the pattern transform by the camera position so it stays fixed in document space (not viewport space).

**Pros:**
- Minimal change to existing pipeline — only the `renderStrokeToContext` method changes
- `createPattern()` is GPU-accelerated and fast
- Two fill operations per stroke, both hardware-accelerated
- Pattern created once and cached
- No offscreen canvas allocation needed
- Physically correct: grain is anchored to the paper

**Cons:**
- `clip()` can be expensive on complex paths (mitigated: our Path2D outlines are not very complex)
- Can't easily vary grain density within a single stroke (whole stroke gets same grain intensity)
- Composite mode switch may flush GPU pipeline

**Performance:** Excellent. Well within the 8ms frame budget on iPad Pro (120Hz). Estimated ~1-2ms overhead per stroke.

---

### Approach 2: Offscreen Canvas Composite (More Control)

**How it works:** Render the stroke to a temporary canvas, composite grain texture using `source-atop` or `destination-out`, then blit to the main canvas.

**Implementation:**
```typescript
// Get pooled offscreen canvas sized to stroke bounding box
const temp = canvasPool.acquire(bboxW, bboxH);
const tempCtx = temp.getContext("2d")!;

// 1. Fill stroke shape
tempCtx.fillStyle = color;
tempCtx.fill(translatedPath);

// 2. Apply grain inside stroke using source-atop
tempCtx.globalCompositeOperation = "source-atop";
tempCtx.fillStyle = grainPattern;
tempCtx.fillRect(0, 0, bboxW, bboxH);

// 3. Blit to main canvas
ctx.drawImage(temp, bboxX, bboxY);

canvasPool.release(temp);
```

**Important Safari caveat:** `OffscreenCanvas` 2D context has incomplete support in Safari/iOS. Use regular hidden `<canvas>` elements instead of `OffscreenCanvas` for compatibility.

**Pros:**
- Full compositing control — can chain multiple effects
- Grain is in document space (no swimming)
- More composite modes available (`source-atop`, `destination-out`, `multiply`)

**Cons:**
- Extra canvas allocation (mitigated with pooling)
- Three draw operations per stroke (fill + composite + blit)
- ~30-50% slower than Approach 1

**Verdict:** Good fallback if `clip()` has issues. More flexible for future effects.

---

### Approach 3: Stamp/Scatter Rendering (Highest Quality)

**How it works:** Render strokes as a series of small textured "stamps" placed along the path, like Procreate/Krita.

**Key parameters** (from Procreate research):
- **Spacing**: distance between stamps. For pencil: 2-5% of stamp size (very dense)
- **Scatter**: lateral offset from center path for edge roughness
- **Opacity jitter**: random per-stamp opacity variation
- **Rotation jitter**: per-stamp rotation for grain direction variation
- **Size jitter**: tied to pressure

**Implementation concept:**
```typescript
for (const point of strokePoints) {
  const stampSize = point.width * 2;
  ctx.save();
  ctx.translate(point.x, point.y);
  ctx.rotate(point.angle + rotationJitter());
  ctx.globalAlpha = point.opacity * opacityJitter();
  ctx.drawImage(stampImage, -stampSize/2, -stampSize/2, stampSize, stampSize);
  ctx.restore();
}
```

**Pros:**
- Industry standard — this is how all professional drawing apps work
- Full per-point control: size, rotation, opacity, scatter
- Natural pressure variation
- Can simulate both pencil grain and brush bristle effects

**Cons:**
- Requires parallel rendering pipeline — cannot use `perfect-freehand` Path2D approach
- 50-200+ `drawImage` calls per stroke segment
- No Path2D caching — need different caching strategy
- `save()`/`restore()` per stamp adds overhead

**Performance mitigations:**
- Pre-render stamps on offscreen canvases
- `Math.round()` coordinates to avoid anti-aliasing overhead
- Batch stamps by minimizing state changes
- At 64x64 stamp, 4px spacing: ~25 stamps per 100px stroke segment — manageable

**Verdict:** Most powerful, but requires a parallel `renderMode` in PenConfig. Good Phase 2 target.

---

### Approach 4: WebGL Fragment Shader (Maximum Performance)

**How it works:** Render strokes to Canvas 2D normally, upload as WebGL texture, apply grain via fragment shader.

```glsl
uniform sampler2D strokeTexture;
uniform sampler2D grainTexture;
uniform float grainStrength;
varying vec2 vUv;

void main() {
  vec4 stroke = texture2D(strokeTexture, vUv);
  vec4 grain = texture2D(grainTexture, vUv * grainScale);
  vec4 result = stroke * mix(vec4(1.0), grain, grainStrength);
  result.a = stroke.a;
  gl_FragColor = result;
}
```

**Reference:** [Canvas2DtoWebGL](https://github.com/jagenjo/Canvas2DtoWebGL) bridges Canvas 2D API to WebGL, enabling hybrid rendering.

**Pros:** GPU-parallel grain computation, procedural noise (no tiling), per-pixel control
**Cons:** Significant architectural complexity, WebGL context management, mixing 2D+GL compositing

**Verdict:** Upgrade path if Canvas 2D approaches prove insufficient. Not needed initially.

---

## Grain Texture Generation

### Recommended Library: `simplex-noise`

[simplex-noise.js](https://github.com/jwagner/simplex-noise.js) — TypeScript-native, zero dependencies, ~2KB minified:
- `createNoise2D()`, `createNoise3D()`, `createNoise4D()` — returns values in [-1, 1]
- ~20 nanoseconds per sample — fast enough for real-time generation
- Install: `yarn add simplex-noise`

### Making Tileable Textures (4D Torus Mapping)

The key technique for seamless tiling uses 4D noise sampled on a torus. Map 2D pixel coordinates to two circles in 4D space:

```typescript
import { createNoise4D } from "simplex-noise";

const noise4D = createNoise4D();
const size = 256;
const scale = 1.5; // Controls grain size
const imageData = ctx.createImageData(size, size);

for (let y = 0; y < size; y++) {
  for (let x = 0; x < size; x++) {
    const nx = x / size;
    const ny = y / size;

    // Sample 4D noise on a torus for seamless tiling
    const value = noise4D(
      Math.cos(nx * 2 * Math.PI) * scale,
      Math.sin(nx * 2 * Math.PI) * scale,
      Math.cos(ny * 2 * Math.PI) * scale,
      Math.sin(ny * 2 * Math.PI) * scale
    );

    // Map [-1, 1] to grayscale for paper grain
    const brightness = Math.floor((value * 0.5 + 0.5) * 255);
    const i = (y * size + x) * 4;
    imageData.data[i] = brightness;
    imageData.data[i + 1] = brightness;
    imageData.data[i + 2] = brightness;
    imageData.data[i + 3] = 255;
  }
}
ctx.putImageData(imageData, 0, 0);
```

### Paper Grain Characteristics

For realistic paper grain (not TV static):
- **Multiple octaves** (fractal Brownian motion): blend 2-3 octaves of noise at different frequencies. Low-frequency = broad paper "tooth", high-frequency = micro-grain
- **Low contrast**: map noise to a narrow range (e.g., alpha 0.85-1.0 for subtle grain, or luminance variation of 5-15%)
- **Anisotropic stretching**: real paper grain has slight directional bias — scale x/y inputs differently
- **Write directly to ImageData**: loop through `imageData.data[index]` rather than using `fillRect` per pixel — dramatically faster

Sources: [simplex-noise.js](https://github.com/jwagner/simplex-noise.js), [Creating Tileable Noise Maps](https://ronvalstar.nl/creating-tileable-noise-maps/), [simplex-noise issue #29](https://github.com/jwagner/simplex-noise.js/issues/29)

---

## Performance Constraints (iPad-Specific)

### Hard Limits

| Constraint | Value | Source |
|-----------|-------|--------|
| Canvas memory limit | ~256MB (iPad) | [WebKit Bug #195325](https://bugs.webkit.org/show_bug.cgi?id=195325) |
| Max canvas pixel area | 16,777,216 px (4096x4096) | [PQINA](https://pqina.nl/blog/canvas-area-exceeds-the-maximum-limit) |
| Pencil input rate | 240Hz (120Hz low power) | [Apple Forums](https://developer.apple.com/forums/thread/689375) |
| Recommended texture size | 512x512 max | Konva.js iOS testing |
| Frame budget (120Hz) | ~8.3ms per frame | iPad Pro display refresh |
| Frame budget (60Hz) | ~16.6ms per frame | Standard iPad display |

### Critical Performance Rules

1. **Generate grain texture once at startup.** Never regenerate per-frame.
2. **Cache `createPattern()` result.** Re-creating patterns per-frame kills throughput.
3. **Round coordinates** with `Math.floor()` to avoid sub-pixel anti-aliasing overhead.
4. **Minimize composite mode changes.** Each switch may flush the GPU pipeline. Batch same-mode operations.
5. **Size offscreen canvases to bounding box**, not full canvas size.
6. **Never use `getImageData`/`putImageData` at render time.** Forces CPU-GPU sync. Use composite ops + `drawImage` instead.
7. **Do NOT set `willReadFrequently: true`** — disables GPU acceleration, adds ~35ms penalty to draws. Only saves ~2ms on reads.
8. **Use hidden `<canvas>` elements, not `OffscreenCanvas`** — Safari/iOS has incomplete `OffscreenCanvas` 2D support.
9. **LOD: skip texture at zoom-out levels.** Grain isn't visible when zoomed out. Skip at LOD 1+.

### Estimated Frame Budget for Textured Pencil Stroke

| Operation | Time |
|-----------|------|
| Input processing | <1ms |
| Path generation (perfect-freehand) | <1ms |
| Solid fill | ~1ms |
| Clip + pattern overlay | ~1-2ms |
| **Total** | **~3-5ms** |

Well within the 8.3ms budget, leaving headroom for GC and browser overhead.

Sources: [MDN: Optimizing Canvas](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Optimizing_canvas), [Understanding willReadFrequently](https://www.schiener.io/2024-08-02/canvas-willreadfrequently), [Konva iOS 15 Issues](https://github.com/konvajs/konva/issues/1182)

---

## Recommended Architecture

### Phase 1: Clip + Pattern Grain (Approach 1)

Minimal-change approach that integrates directly into `Renderer.renderStrokeToContext`:

1. **At plugin load**: generate a tileable 256x256 grain texture using `simplex-noise` with 4D torus mapping. Write to a hidden `<canvas>`, create `CanvasPattern` via `createPattern("repeat")`. Generate a second variant for dark-mode pages (inverted grain).

2. **In `PenConfig`**: add optional `grainConfig` field:
   ```typescript
   grainConfig?: {
     intensity: number;      // 0-1, how much grain affects the stroke
     scale: number;          // grain tile scale factor
     pressureResponse: number; // how much pressure reduces grain (0-1)
   }
   ```

3. **In `Renderer.renderStrokeToContext`**: for pens with `grainConfig`:
   ```
   ctx.save()
   ctx.fillStyle = color
   ctx.globalAlpha = opacity
   ctx.fill(path)                           // solid fill
   ctx.clip(path)                            // clip to stroke
   ctx.globalCompositeOperation = 'multiply'
   ctx.globalAlpha = grainIntensity * (1 - pressure * pressureResponse)
   ctx.fillStyle = grainPattern
   // Transform pattern to document space (offset by camera)
   ctx.setTransform(...)
   ctx.fillRect(bounds)
   ctx.restore()
   ```

4. **LOD integration**: skip grain at LOD 1+ (already not visible when zoomed out).

5. **Active stroke optimization**: optionally skip grain during active drawing (apply on bake-to-static only) if performance is tight.

### Phase 1b: Brush Grain Variant

Same technique with a directional bristle-streak texture instead of random grain. Generate by stretching noise in one axis.

### Phase 2: Stamp Engine (Future)

Add `renderMode: "fill" | "stamp"` to `PenConfig`. Pens with `"stamp"` mode bypass perfect-freehand and use a stamp engine. Coexists with existing fill pipeline.

---

## Interaction with Existing Systems

| System | Impact |
|--------|--------|
| **Path2D caching** | Preserved — outline generation unchanged |
| **LOD system** | Natural integration — skip grain at LOD 1+ |
| **Spatial index** | No impact — culling works the same |
| **Undo/redo** | No impact — strokes store the same data |
| **Ink pooling** | No interaction (fountain pen only) |
| **Dark mode** | Generate inverted grain texture for dark pages |
| **Highlighter compositing** | No conflict — highlighter doesn't use grain |
| **Prediction layer** | Skip grain for predictions (already semi-transparent) |

---

## Key Risks

1. **Performance on older iPads** — `clip()` + pattern fill may be slower on A10/A11 chips. Mitigation: grain as a settings toggle; skip at LOD 1+; defer to bake-to-static.

2. **`clip()` cost on complex paths** — Path2D from perfect-freehand can have many points. Mitigation: use simplified paths at LOD 1+; `clip()` is generally well-optimized for filled shapes.

3. **Pattern transform alignment** — The grain pattern must be offset by camera position to stay anchored in document space. Requires `ctx.setTransform()` or pattern matrix transform.

4. **Visual tuning** — Getting grain to look "right" requires iteration. Too much = noise; too little = invisible. Plan for tuning time.

5. **Safari `OffscreenCanvas` limitations** — If we need Approach 2 later, must use hidden `<canvas>` elements, not `OffscreenCanvas`.

---

## Reference Sources

### Open Source Projects
- [simplex-noise.js](https://github.com/jwagner/simplex-noise.js) — Noise generation library (recommended)
- [perfect-freehand](https://github.com/steveruizok/perfect-freehand) — Stroke outline library (already used)
- [p5.brush](https://github.com/acamposuribe/p5.brush) — Sophisticated brush engine with texture (study for algorithms)
- [p5.grain](https://github.com/meezwhite/p5.grain) — Grain overlay techniques for canvas
- [PWA Inking](https://github.com/pwa-builder/pwa-inking) — Microsoft's low-latency inking web component
- [Canvas2DtoWebGL](https://github.com/jagenjo/Canvas2DtoWebGL) — Hybrid Canvas 2D/WebGL bridge
- [WickBrush](https://github.com/Wicklets/WickBrush) — Spring-physics brush with stamp tips
- [Rough.js](https://roughjs.com/) — Excalidraw's hand-drawn style (path distortion, not texture)

### Articles & Documentation
- [Exploring Canvas Drawing Techniques](https://perfectionkills.com/exploring-canvas-drawing-techniques/) — Comprehensive Canvas 2D brush techniques
- [All About That Grain (fxhash)](https://www.fxhash.xyz/article/all-about-that-grain) — Grain technique comparison with performance analysis
- [How to Implement a Basic Bitmap Brush](https://losingfight.com/blog/2007/08/18/how-to-implement-a-basic-bitmap-brush/) — Stamp-based brush fundamentals
- [Creating Tileable Noise Maps](https://ronvalstar.nl/creating-tileable-noise-maps/) — 4D torus technique walkthrough
- [Krita Texture Documentation](https://docs.krita.org/en/reference_manual/brushes/brush_settings/texture.html) — Open-source brush texture modes
- [MDN: Compositing and Clipping](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing) — Canvas composite operations reference
- [MDN: Optimizing Canvas](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Optimizing_canvas) — Canvas performance best practices
- [Understanding willReadFrequently](https://www.schiener.io/2024-08-02/canvas-willreadfrequently) — Critical iOS Canvas 2D performance gotcha
- [Procreate Brush Studio Settings](https://help.procreate.com/procreate/handbook/brushes/brush-studio-settings) — Professional brush engine reference

### Academic Papers
- [Real-Time Pencil Rendering (Lee et al., 2006)](https://static.aminer.org/pdf/PDF/000/519/757/real_time_pencil_rendering.pdf) — GPU pencil rendering with texture screening
- [Observational Models of Graphite Pencil Materials (Sousa & Buchanan, 2000)](https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.00386) — Physical model of pencil-paper interaction
- [Texture Screening Method for Fast Pencil Rendering](https://www.researchgate.net/publication/267257799_Texture_Screening_Method_for_Fast_Pencil_Rendering) — Optimized pencil texture approach

---

## Conclusion

**Feasibility: High.** The recommended approach (Clip + Pattern Fill) adds pencil grain texture with minimal changes to the existing architecture:

- **2 extra Canvas API calls per stroke** (clip + pattern fill) — both GPU-accelerated
- **~1-2ms additional render time per stroke** — well within iPad frame budget
- **Zero changes** to Path2D generation, caching, LOD, spatial index, or undo/redo
- **`simplex-noise` library** for generating realistic tileable paper grain at startup
- **Screen-space grain is physically correct** — paper grain doesn't move with the pencil

No web-based drawing app (Excalidraw, tldraw) currently implements pencil grain textures — they all use solid fills from perfect-freehand. Adding this would differentiate ObsidianPaper. The Krita and Procreate approaches (texture multiply/subtract modes) provide well-proven algorithms to reference.
